{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "import models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMINE = 1\n",
    "SEED = 22\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gender_as_num(gender):\n",
    "    if gender == \"male\":\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_age_group(age): # HIGH NOTE: changing each of the scalars to a vector. This is probably not a good idea\n",
    "    if age < 18:\n",
    "        # 13 - 17\n",
    "        return [1, 0, 0]\n",
    "    elif age < 28:\n",
    "        # 23 - 27\n",
    "        return [0, 1, 0]\n",
    "    elif age < 49:\n",
    "        # 33 - 48\n",
    "        return [0, 0, 1]\n",
    "    else:\n",
    "        return [0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "so wuts up? today i had the parade. suked. but it wasnt that bad. im done with band for the year. we had a battle today. we kicked ass.  they had nothing.  then jims party.  then my snotty little cousins bday party. i dun like her. sublime. out.\n",
      "[18, 33, 97, 2, 43, 1, 3529, 17, 9, 1809, 8, 177, 200, 234, 20, 548, 13, 1, 169, 23, 43, 5, 1776, 97, 23, 2024, 457, 36, 43, 203, 56, 387, 56, 10, 16243, 122, 3032, 4481, 387, 2, 1020, 29, 49, 11763, 32]\n"
     ]
    }
   ],
   "source": [
    "blog_posts_data_dir = \"data/blogs/json-data/\"\n",
    "train_file_name = \"train.json\"\n",
    "test_file_name = \"test.json\"\n",
    "\n",
    "# Load data\n",
    "with open(blog_posts_data_dir + train_file_name) as r:\n",
    "    training_set = json.load(r)\n",
    "    print(training_set[EXAMINE][\"post\"])\n",
    "\n",
    "# Map each word to a unique int value\n",
    "MAX_WORD_COUNT = 20000\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words = MAX_WORD_COUNT)\n",
    "posts = [instance[\"post\"] for instance in training_set]\n",
    "tokenizer.fit_on_texts(posts)\n",
    "sequences = tokenizer.texts_to_sequences(posts)\n",
    "for i, instance in enumerate(training_set):\n",
    "    instance[\"post\"] = sequences[i]\n",
    "    instance[\"gender\"] = get_gender_as_num(instance[\"gender\"])\n",
    "    instance[\"age\"] = get_age_group(int(instance[\"age\"]))\n",
    "print(training_set[EXAMINE][\"post\"])\n",
    "\n",
    "# def prepare_sequence(seq, word_to_int):\n",
    "#     ints = [word_to_int[w] for w in seq]\n",
    "#     return torch.tensor(ints, dtype = torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word_to_int.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Key Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_count = len(training_set)\n",
    "\n",
    "categories_count = len(training_set[0][\"age\"])\n",
    "\n",
    "samples_per_class = {0 : 0, 1 : 0, 2 : 0}\n",
    "for instance in training_set:\n",
    "    for i, a in enumerate(instance[\"age\"]):\n",
    "        if a == 1:\n",
    "            samples_per_class[i] += 1\n",
    "            break\n",
    "\n",
    "median_words_per_sample = np.median([len(instance[\"post\"]) for instance in training_set])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples: 526812\n",
      "Number of Categories: 3\n",
      "Samples per Class: {0: 177940, 1: 250672, 2: 98200}\n",
      "Median Words per Sample: 121.0\n",
      "Samples to Words Per Sample Ratio: 4353.818181818182\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Samples:\", samples_count)\n",
    "print(\"Number of Categories:\", categories_count)\n",
    "print(\"Samples per Class:\", samples_per_class)\n",
    "print(\"Median Words per Sample:\", median_words_per_sample)\n",
    "print(\"Samples to Words Per Sample Ratio:\", samples_count / median_words_per_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(list(length_distribution.keys()))\n",
    "# plt.xlabel(\"Length of a Sample\")\n",
    "# plt.ylabel(\"Number of samples\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[An Introduction to Different Types of Convolutions](https://towardsdatascience.com/types-of-convolutions-in-deep-learning-717013397f4d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "EMBEDDING_DIM = 50\n",
    "\n",
    "# Input, Embedding, Conv, Conv, Conv, Dense, Dense\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "# TODO: Import GloVe embeddings\n",
    "# TODO: Create validation set\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, EMBEDDING_DIM, input_length = median_words_per_sample))\n",
    "model.add(tf.keras.layers.SeparableConv1D())\n",
    "model.add(tf.keras.layers.SeparableConv1D())\n",
    "model.add(tf.keras.layers.SeparableConv1D())\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense())\n",
    "model.add(tf.keras.layers.Dense())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.compile(optimizer = \"rmsprop\", loss = \"categorical_crossentropy\", metrics = [\"acc\"])\n",
    "model.summary()\n",
    "history = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
