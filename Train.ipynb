{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "import models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMINE = 21\n",
    "SEED = 22\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gender_as_num(gender):\n",
    "    if gender == \"male\":\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_age_group(age): # HIGH NOTE: changing each of the scalars to a vector. This is probably not a good idea\n",
    "    if age < 18:\n",
    "        # 13 - 17\n",
    "        return [1, 0, 0]\n",
    "    elif age < 28:\n",
    "        # 23 - 27\n",
    "        return [0, 1, 0]\n",
    "    elif age < 49:\n",
    "        # 33 - 48\n",
    "        return [0, 0, 1]\n",
    "    else:\n",
    "        return [0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "blog_posts_data_dir = \"data/blogs/json-data/\"\n",
    "train_file_name = \"train.json\"\n",
    "test_file_name = \"test.json\"\n",
    "\n",
    "# Load data\n",
    "with open(blog_posts_data_dir + train_file_name) as r:\n",
    "    training_set = json.load(r)\n",
    "raw_posts = [instance[\"post\"] for instance in training_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The kids had a great time at the pool yesterday afternoon splashing around and diving for pennies.  While we were there, a reporter came around from the local paper and was snapping pictures of the kids and taking names.  He took special interest in the fact it was my son's birthday and took some extra pictures of him and his brother.  So, I guess I need to check out this weekend's edition of the paper to see if the kids pictures show up.  The children would get a real kick out of it to see their pictures in the newspaper.    My son also got to take treats to his church group last night and they all sang \"Happy Birthday\" to him - he loved the attention!  The leaders at that group are amazing!  The staff members that are men are wonderful role models for both the children.  Until we meet again......\n"
     ]
    }
   ],
   "source": [
    "print(raw_posts[EXAMINE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_words_per_sample = np.median([len(instance[\"post\"]) for instance in training_set])\n",
    "\n",
    "# Map each word to a unique int value\n",
    "MAX_WORD_COUNT = 20000\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words = MAX_WORD_COUNT)\n",
    "posts = [instance[\"post\"] for instance in training_set]\n",
    "tokenizer.fit_on_texts(posts)\n",
    "word_index = dict(list(tokenizer.word_index.items())[:20000])\n",
    "sequences = tokenizer.texts_to_sequences(posts)\n",
    "median_words_per_tokenized_sample = np.median([len(post) for post in sequences])\n",
    "data = tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen = int(median_words_per_tokenized_sample),\n",
    "                                                     padding = \"post\")\n",
    "for i, instance in enumerate(training_set):\n",
    "    instance[\"post\"] = data[i]\n",
    "    instance[\"gender\"] = get_gender_as_num(instance[\"gender\"])\n",
    "    instance[\"age\"] = get_age_group(int(instance[\"age\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  255   679  1211     7     1   323     9    14    10 10313   533     4\n",
      "   255    55  1119   604     6    79     4    58   608    18     2   211\n",
      "     2   140     3   434    32    19 15890  3749     6     1   671     3\n",
      "    85    40     1   397   604   262    33     1   605    67    44     5\n",
      "   311  1251    32     6     9     3    85    91   604     7     1  2458\n",
      "    10   983   129    77     3   139  5998     3    58   545   480   102\n",
      "   125     4    36    26  2704   225   533     3    79    27   708     1\n",
      "   860     1  2608    24     8   480    30   653     1  1744  1148     8\n",
      "    30   499    30   741  1638  5324    13   282     1   605   227    23\n",
      "   554   130]\n",
      "[0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(training_set[EXAMINE][\"post\"])\n",
    "print(training_set[EXAMINE][\"age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 1), ('i', 2), ('to', 3), ('and', 4), ('a', 5), ('of', 6), ('in', 7), ('that', 8), ('it', 9), ('my', 10), ('is', 11), ('you', 12), ('for', 13), ('was', 14), ('on', 15), ('me', 16), ('but', 17), ('so', 18), ('this', 19), ('with', 20), ('have', 21), ('be', 22), ('we', 23), ('at', 24), ('not', 25), ('all', 26), ('he', 27), ('as', 28), ('like', 29), ('are', 30), ('just', 31), ('out', 32), ('up', 33), ('about', 34), (\"i'm\", 35), ('they', 36), ('what', 37), ('or', 38), ('one', 39), ('if', 40), ('from', 41), ('do', 42), ('had', 43), ('get', 44), ('when', 45), ('urllink', 46), ('will', 47), ('there', 48), ('her', 49), ('she', 50), ('time', 51), ('know', 52), ('now', 53), ('can', 54), ('some', 55), ('then', 56), ('by', 57), ('his', 58), (\"it's\", 59), ('really', 60), ('no', 61), ('an', 62), ('your', 63), ('go', 64), ('more', 65), ('am', 66), ('would', 67), ('think', 68), (\"don't\", 69), ('well', 70), ('who', 71), ('people', 72), ('good', 73), ('been', 74), ('has', 75), ('how', 76), ('got', 77), ('were', 78), ('him', 79), ('them', 80), ('back', 81), ('going', 82), ('because', 83), ('day', 84), ('see', 85), ('much', 86), ('our', 87), ('only', 88), ('which', 89), ('want', 90), ('their', 91), ('love', 92), ('even', 93), ('after', 94), ('other', 95), ('too', 96), ('today', 97), ('went', 98), ('over', 99), ('way', 100)]\n"
     ]
    }
   ],
   "source": [
    "print(list(word_index.items())[ : 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Key Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_count = len(training_set)\n",
    "\n",
    "categories_count = len(training_set[0][\"age\"])\n",
    "\n",
    "samples_per_class = {0 : 0, 1 : 0, 2 : 0}\n",
    "for instance in training_set:\n",
    "    for i, a in enumerate(instance[\"age\"]):\n",
    "        if a == 1:\n",
    "            samples_per_class[i] += 1\n",
    "            break\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples: 526812\n",
      "Number of Categories: 3\n",
      "Samples per Class: {0: 177940, 1: 250672, 2: 98200}\n",
      "Median Words per Sample: 621.0\n",
      "Median Words per Tokenized Sample: 110.0\n",
      "Samples to Words Per Sample Ratio: 4789.2\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Samples:\", samples_count)\n",
    "print(\"Number of Categories:\", categories_count)\n",
    "print(\"Samples per Class:\", samples_per_class)\n",
    "print(\"Median Words per Sample:\", median_words_per_sample)\n",
    "print(\"Median Words per Tokenized Sample:\", median_words_per_tokenized_sample)\n",
    "print(\"Samples to Words Per Sample Ratio:\", samples_count / median_words_per_tokenized_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(list(length_distribution.keys()))\n",
    "# plt.xlabel(\"Length of a Sample\")\n",
    "# plt.ylabel(\"Number of samples\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Pretrained Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 50\n",
    "\n",
    "glove_path = \"data/embeddings/glove.6B/\"\n",
    "glove_dict = {}\n",
    "with open(glove_path + \"glove.6B.50d.txt\") as f:\n",
    "    for line in f:\n",
    "        line_values = line.split(\" \")\n",
    "        word = line_values[0]\n",
    "        embedding_coefficients = np.asarray(line_values[1 : ], dtype = \"float32\")\n",
    "        glove_dict[word] = embedding_coefficients\n",
    "\n",
    "glove_weights = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    glove_vector = glove_dict.get(word)\n",
    "    if glove_vector is not None:\n",
    "        glove_weights[i] = glove_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20001\n"
     ]
    }
   ],
   "source": [
    "print(len(glove_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[An Introduction to Different Types of Convolutions](https://towardsdatascience.com/types-of-convolutions-in-deep-learning-717013397f4d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "# Input, Embedding, Conv, Pool, Conv, Pool, Flatten, Dense, Dense\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(len(word_index) + 1, EMBEDDING_DIM, weights = [glove_weights],\n",
    "                                    input_length = median_words_per_tokenized_sample, trainable = True))\n",
    "model.add(tf.keras.layers.SeparableConv1D(50, 5, activation = \"relu\"))\n",
    "model.add(tf.keras.layers.MaxPooling1D())\n",
    "model.add(tf.keras.layers.SeparableConv1D(100, 3, activation = \"relu\"))\n",
    "model.add(tf.keras.layers.MaxPooling1D())\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(24, activation = \"sigmoid\"))\n",
    "model.add(tf.keras.layers.Dense(3, activation = \"softmax\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_train = np.array([instance[\"post\"] for instance in training_set])\n",
    "ages_train = np.array([instance[\"age\"] for instance in training_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 110, 50)           1000050   \n",
      "_________________________________________________________________\n",
      "separable_conv1d_4 (Separabl (None, 106, 50)           2800      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 53, 50)            0         \n",
      "_________________________________________________________________\n",
      "separable_conv1d_5 (Separabl (None, 51, 100)           5250      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 25, 100)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2500)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 24)                60024     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 75        \n",
      "=================================================================\n",
      "Total params: 1,068,199\n",
      "Trainable params: 1,068,199\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomas/Machine-Learning-Virtualenv/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 421449 samples, validate on 105363 samples\n",
      "Epoch 1/10\n",
      "421449/421449 [==============================] - 136s 323us/step - loss: 0.8995 - acc: 0.5747 - val_loss: 0.8497 - val_acc: 0.6055\n",
      "Epoch 2/10\n",
      "421449/421449 [==============================] - 147s 348us/step - loss: 0.8261 - acc: 0.6178 - val_loss: 0.8170 - val_acc: 0.6237\n",
      "Epoch 3/10\n",
      "421449/421449 [==============================] - 143s 339us/step - loss: 0.7909 - acc: 0.6377 - val_loss: 0.7949 - val_acc: 0.6358\n",
      "Epoch 4/10\n",
      "421449/421449 [==============================] - 146s 346us/step - loss: 0.7664 - acc: 0.6516 - val_loss: 0.7888 - val_acc: 0.6395\n",
      "Epoch 5/10\n",
      "421449/421449 [==============================] - 146s 346us/step - loss: 0.7469 - acc: 0.6629 - val_loss: 0.7730 - val_acc: 0.6466\n",
      "Epoch 6/10\n",
      "421449/421449 [==============================] - 143s 340us/step - loss: 0.7315 - acc: 0.6714 - val_loss: 0.7870 - val_acc: 0.6351\n",
      "Epoch 7/10\n",
      "421449/421449 [==============================] - 139s 330us/step - loss: 0.7180 - acc: 0.6785 - val_loss: 0.7750 - val_acc: 0.6457\n",
      "Epoch 8/10\n",
      "421449/421449 [==============================] - 138s 328us/step - loss: 0.7057 - acc: 0.6860 - val_loss: 0.7690 - val_acc: 0.6453\n",
      "Epoch 9/10\n",
      "421449/421449 [==============================] - 138s 328us/step - loss: 0.6939 - acc: 0.6923 - val_loss: 0.7774 - val_acc: 0.6399\n",
      "Epoch 10/10\n",
      "421449/421449 [==============================] - 138s 327us/step - loss: 0.6826 - acc: 0.6984 - val_loss: 0.7683 - val_acc: 0.6466\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = \"rmsprop\", loss = \"categorical_crossentropy\", metrics = [\"acc\"])\n",
    "model.summary()\n",
    "history = model.fit(posts_train, ages_train, epochs = 10, batch_size = 500, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = \"models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(models_dir + \"2sep-conv_2dense.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "with open(blog_posts_data_dir + test_file_name) as r:\n",
    "    test_set = json.load(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_posts = [instance[\"post\"] for instance in test_set]\n",
    "test_sequences = tokenizer.texts_to_sequences(test_posts)\n",
    "test_post_data = tf.keras.preprocessing.sequence.pad_sequences(test_sequences, maxlen = int(median_words_per_tokenized_sample),\n",
    "                                                     padding = \"post\")\n",
    "for i, instance in enumerate(test_set):\n",
    "    instance[\"post\"] = test_post_data[i]\n",
    "    instance[\"gender\"] = get_gender_as_num(instance[\"gender\"])\n",
    "    instance[\"age\"] = get_age_group(int(instance[\"age\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_test = np.array([instance[\"post\"] for instance in test_set])\n",
    "ages_test = np.array([instance[\"age\"] for instance in test_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131703/131703 [==============================] - 13s 98us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7650201190724795, 0.6507368852632148]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(posts_test, ages_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
